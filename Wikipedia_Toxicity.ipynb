{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Wikipedia_Toxicity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A81YUL5Srbxk"
      },
      "source": [
        "DESCRIPTION\n",
        "\n",
        "    Using NLP and machine learning, make a model to identify toxic comments from the Talk edit pages on Wikipedia. Help identify the 0swords that make a comment toxic.\n",
        "\n",
        "Problem Statement:  \n",
        "\n",
        "    Wikipedia is the world’s largest and most popular reference work on the internet with about 500 million unique visitors per month. It also has millions of contributors who can make edits to pages. The Talk edit pages, the key community interaction forum where the contributing community interacts or discusses or debates about the changes pertaining to a particular topic. \n",
        "\n",
        "    Wikipedia continuously strives to help online discussion become more productive and respectful. You are a data scientist at Wikipedia who will help Wikipedia to build a predictive model that identifies toxic comments in the discussion and marks them for cleanup by using NLP and machine learning. Post that, help identify the top terms from the toxic comments. \n",
        "\n",
        "Domain: Internet\n",
        "\n",
        "    Analysis to be done: Build a text classification model using NLP and machine learning that detects toxic comments.\n",
        "\n",
        "Content: \n",
        "\n",
        "    id: identifier number of the comment\n",
        "\n",
        "    comment_text: the text in the comment\n",
        "\n",
        "    toxic: 0 (non-toxic) /1 (toxic)\n",
        "\n",
        "Steps to perform:\n",
        "\n",
        "    Cleanup the text data, using TF-IDF convert to vector space representation, use Support Vector Machines to detect toxic comments. Finally, get the list of top 15 toxic terms from the comments identified by the model.\n",
        "\n",
        "Tasks: \n",
        "\n",
        "    Load the data using read_csv function from pandas package\n",
        "\n",
        "    Get the comments into a list, for easy text cleanup and manipulation\n",
        "\n",
        "Cleanup: \n",
        "\n",
        "    Using regular expressions, remove IP addresses\n",
        "\n",
        "    Using regular expressions, remove URLs\n",
        "\n",
        "    Normalize the casing\n",
        "\n",
        "    Tokenize using word_tokenize from NLTK\n",
        "\n",
        "    Remove stop words\n",
        "\n",
        "    Remove punctuation\n",
        "\n",
        "    Define a function to perform all these steps, you’ll use this later on the actual test set\n",
        "\n",
        "    Using a counter, find the top terms in the data. \n",
        "\n",
        "    Can any of these be considered contextual stop words? \n",
        "\n",
        "    Words like “Wikipedia”, “page”, “edit” are examples of contextual stop words\n",
        "\n",
        "    If yes, drop these from the data\n",
        "\n",
        "Train-Test Split:\n",
        "\n",
        "    Separate into train and test sets\n",
        "\n",
        "    Use train-test method to divide your data into 2 sets: train and test\n",
        "\n",
        "    Use a 70-30 split\n",
        "\n",
        "Tf-idf transofrmation\n",
        "\n",
        "    Use TF-IDF values for the terms as feature to get into a vector space model\n",
        "\n",
        "    Import TF-IDF vectorizer from sklearn\n",
        "\n",
        "    Instantiate with a maximum of 4000 terms in your vocabulary\n",
        "\n",
        "    Fit and apply on the train set\n",
        "\n",
        "    Apply on the test set\n",
        "\n",
        "Model building: Support Vector Machine\n",
        "\n",
        "    Instantiate SVC from sklearn with a linear kernel\n",
        "\n",
        "    Fit on the train data\n",
        "\n",
        "    Make predictions for the train and the test set\n",
        "\n",
        "    Model evaluation: Accuracy, recall, and f1_score\n",
        "\n",
        "    Report the accuracy on the train set\n",
        "\n",
        "    Report the recall on the train set:decent, high, low?\n",
        "\n",
        "    Get the f1_score on the train set\n",
        "\n",
        "Looks like you need to adjust  the class imbalance, as the model seems to focus on the 0s\n",
        "\n",
        "    Adjust the appropriate parameter in the SVC module\n",
        "\n",
        "    Train again with the adjustment and evaluate\n",
        "\n",
        "    Train the model on the train set\n",
        "\n",
        "    Evaluate the predictions on the validation set: accuracy, recall, f1_score\n",
        "\n",
        "Hyperparameter tuning\n",
        "\n",
        "    Import GridSearch and StratifiedKFold (because of class imbalance)\n",
        "\n",
        "    Provide the parameter grid to choose for ‘C’\n",
        "\n",
        "    Use a balanced class weight while instantiating the Support Vector Classifier\n",
        "\n",
        "    Find the parameters with the best recall in cross validation\n",
        "\n",
        "    Choose ‘recall’ as the metric for scoring\n",
        "\n",
        "    Choose stratified 5 fold cross validation scheme\n",
        "\n",
        "Fit on the train set\n",
        "\n",
        "    What are the best parameters?\n",
        "\n",
        "    Predict and evaluate using the best estimator\n",
        "\n",
        "    Use best estimator from the grid search to make predictions on the test set\n",
        "\n",
        "    What is the recall on the test set for the toxic comments?\n",
        "\n",
        "    What is the f1_score?\n",
        "\n",
        "    What are the most prominent terms in the toxic comments?\n",
        "\n",
        "Separate the comments from the test set that the model identified as toxic\n",
        "\n",
        "    Make one large list of the terms\n",
        "\n",
        "    Get the top 15 terms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkYqp-me-Fa0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from nltk import word_tokenize\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwRwCb0M-Fa_"
      },
      "source": [
        "data = pd.read_csv(\"wikipedia.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAW6cdVx16Bo",
        "outputId": "0766a519-7506-4afd-8a49-67236b7fdb6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OflXXGCO-FbH",
        "outputId": "95acbfd5-9eb8-4b80-9d5d-2f866dfa1a91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>e617e2489abe9bca</td>\n",
              "      <td>\"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9250cf637294e09d</td>\n",
              "      <td>\"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ce1aa4592d5240ca</td>\n",
              "      <td>Marya Dzmitruk was born in Minsk, Belarus in M...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48105766ff7f075b</td>\n",
              "      <td>\"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0543d4f82e5470b6</td>\n",
              "      <td>New Categories \\r\\n\\r\\nI honestly think that w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text  toxic\n",
              "0  e617e2489abe9bca  \"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...      0\n",
              "1  9250cf637294e09d  \"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...      0\n",
              "2  ce1aa4592d5240ca  Marya Dzmitruk was born in Minsk, Belarus in M...      0\n",
              "3  48105766ff7f075b      \"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"      0\n",
              "4  0543d4f82e5470b6  New Categories \\r\\n\\r\\nI honestly think that w...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM5sAXXxkKOy",
        "outputId": "90410621-7d22-4e06-cbd0-063011baaa26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guZtI9j-piQC"
      },
      "source": [
        "Cleanup: \n",
        "\n",
        "    Using regular expressions, remove IP addresses\n",
        "\n",
        "    Using regular expressions, remove URLs\n",
        "\n",
        "    Normalize the casing\n",
        "\n",
        "    Tokenize using word_tokenize from NLTK\n",
        "\n",
        "    Remove stop words\n",
        "\n",
        "    Remove punctuation\n",
        "\n",
        "    drop contextual words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ii-XB9F-FbR"
      },
      "source": [
        "def textPreProcess(comment_list):\n",
        "    \n",
        "    #Remove IPs\n",
        "    comment_list_without_ip = []\n",
        "    for comment in comment_list:\n",
        "        comment_list_without_ip.append(re.sub('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', '', comment ))\n",
        "\n",
        "    del comment_list\n",
        "\n",
        "    #Remove URLs\n",
        "    comment_list_without_url = []\n",
        "    regex_url = r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))'''\n",
        "    for comment in comment_list_without_ip:\n",
        "        comment_list_without_url.append( re.sub(regex_url, '', comment))    \n",
        "\n",
        "    del comment_list_without_ip\n",
        "\n",
        "    #Remove Punctuation\n",
        "    comment_list_without_punctuation = []\n",
        "    for comment in comment_list_without_url:\n",
        "        removePunctuation = [char for char in comment if char not in string.punctuation]\n",
        "        modifiedcomment = ''.join(removePunctuation)\n",
        "        comment_list_without_punctuation.append(modifiedcomment)\n",
        "\n",
        "    del comment_list_without_url\n",
        "\n",
        "    #Remove StopWords and Normalize\n",
        "    comment_list_without_stopwords = []\n",
        "    for comment in comment_list_without_punctuation:\n",
        "        words = comment.split(\" \")\n",
        "        wordNormalized = [word.lower() for word in words]\n",
        "        finalWords = [word for word in wordNormalized if word not in stopwords.words('english')]\n",
        "        comment_list_without_stopwords.append(' '.join(word for word in finalWords))\n",
        "\n",
        "    del comment_list_without_punctuation\n",
        "\n",
        "    #Remove Contextual StopWords\n",
        "    comment_list_without_context_stopwords = [] \n",
        "    for comment in comment_list_without_stopwords: \n",
        "        words = comment.split(\" \")\n",
        "        wordListWithoutContextualStopWords = [word for word in words if ((not (word.startswith(\"wikipe\"))) and (not (word.startswith(\"wikipi\"))) and\n",
        "                                                                         (not (word.startswith(\"wikipp\")))  and (not (word.startswith(\"edit\"))) and (not (word.startswith(\"page\"))))]\n",
        "        comment_list_without_context_stopwords.append(' '.join(word for word in wordListWithoutContextualStopWords))\n",
        "\n",
        "    del comment_list_without_stopwords\n",
        "\n",
        "    #Tokenize using Word_Tokenizer\n",
        "    sentences = ' '.join(comment for comment in comment_list_without_context_stopwords)\n",
        "    words = word_tokenize(sentences)\n",
        "    \n",
        "    return words, comment_list_without_context_stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwiDiktJ-FbY"
      },
      "source": [
        "comment_list = data['comment_text'].to_list()\n",
        "wordList, commentList = textPreProcess(comment_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD0U_kyfq0z2"
      },
      "source": [
        "Display the top 15 most repeated words "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bBKEmb-ymwk",
        "outputId": "5515e80f-1e6a-4bb1-ef82-8b88a123e77c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "count_words = Counter(wordList)\n",
        "count_words.most_common(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('article', 1659),\n",
              " ('talk', 1047),\n",
              " ('please', 1033),\n",
              " ('would', 965),\n",
              " ('one', 856),\n",
              " ('like', 836),\n",
              " ('dont', 784),\n",
              " ('ass', 709),\n",
              " ('also', 657),\n",
              " ('i', 643),\n",
              " ('think', 630),\n",
              " ('fuck', 630),\n",
              " ('see', 628),\n",
              " ('know', 595),\n",
              " ('im', 561)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khAf1MniyG62"
      },
      "source": [
        "#Build Vocabulary\n",
        "wordVector = CountVectorizer()\n",
        "features = np.array(comment_list)\n",
        "finalWordVocab = wordVector.fit(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nVKHw4PqGow"
      },
      "source": [
        "Seperate Feature and labels and form bagofwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDfZ-Ukx-Fbk"
      },
      "source": [
        "#Seperate data as features and label\n",
        "features = data.iloc[:,1].values\n",
        "label = data.iloc[:,2].values\n",
        "bagOfWords = finalWordVocab.transform(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhSyZY5KEUKu",
        "outputId": "0d8fe0a6-a020-4d76-c8e5-2fb3c5d3322c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "pd.Series(label).value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4563\n",
              "1     437\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zaYMGR8qWS_"
      },
      "source": [
        "Do tfidf transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjnX9BAl-Fbo"
      },
      "source": [
        "#Calc IDF values\n",
        "tfidfObject = TfidfTransformer().fit(bagOfWords)\n",
        "\n",
        "#Transform data \n",
        "finalFeatureApply = tfidfObject.transform(bagOfWords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH5L7hFyqsg0"
      },
      "source": [
        "Split Train and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnmn_Z2m-Fbt"
      },
      "source": [
        "# Apply TrainTestSplit\n",
        "X_train,X_test,y_train,y_test,indices_train,indices_test = train_test_split(finalFeatureApply,\n",
        "                                                                            label,\n",
        "                                                                            range(5000),\n",
        "                                                                            test_size=0.3,\n",
        "                                                                            random_state=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ1jxatl_nxc",
        "outputId": "12388d0f-adf2-48dd-efac-870cad21d80c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape, X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3500, 22886), (1500, 22886), (3500,), (1500,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdBd_XuHqw1-"
      },
      "source": [
        "Scale the data and apply SVC classifier and print the accuracy,precision , Recall and F1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kebF3lBbANYt"
      },
      "source": [
        "scaler = StandardScaler(with_mean=False)\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "clf = SVC(gamma='auto')\n",
        "clf.fit(X_train_scaled, y_train)\n",
        "y_pred = clf.predict(X_test_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeyKfCqBDWYF",
        "outputId": "aeb00695-2ffd-4394-d25a-dc02dfe3c521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "y_train_pred = clf.predict(X_train_scaled)\n",
        "print(\"Train Accuracy: \",metrics.accuracy_score(y_train,y_train_pred)*100)\n",
        "print(\"Train Recall: \",metrics.recall_score(y_train,y_train_pred,average='weighted')*100)\n",
        "print(\"Train f1 score: \",metrics.f1_score(y_train,y_train_pred,average='weighted')*100)\n",
        "print(\"Test Accuracy: \",metrics.accuracy_score(y_test,y_pred)*100)\n",
        "print(\"Test Recall: \",metrics.recall_score(y_test,y_pred,average='weighted')*100)\n",
        "print(\"Test f1 score: \",metrics.f1_score(y_test,y_pred,average='weighted')*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy:  92.82857142857142\n",
            "Train Recall:  92.82857142857142\n",
            "Train f1 score:  90.39978901353544\n",
            "Test Accuracy:  90.93333333333334\n",
            "Test Recall:  90.93333333333334\n",
            "Test f1 score:  86.61527001862197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47Pvh1cgLsVT",
        "outputId": "ee2213fd-e419-4cb2-dcfe-46a5e96f04bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "print(metrics.classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95      1364\n",
            "           1       0.00      0.00      0.00       136\n",
            "\n",
            "    accuracy                           0.91      1500\n",
            "   macro avg       0.45      0.50      0.48      1500\n",
            "weighted avg       0.83      0.91      0.87      1500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMWH7EAtrC8Z"
      },
      "source": [
        "We see that the model only predicts 0 class, doesnt predict 1 class , hence we need to tune hyperparameters and apply different weights for each class. crossvalidate using stratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjBVSjz5WvuB",
        "outputId": "3c1c1673-8477-4a7e-cce6-a08f0178bdba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "clf.get_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1.0,\n",
              " 'break_ties': False,\n",
              " 'cache_size': 200,\n",
              " 'class_weight': None,\n",
              " 'coef0': 0.0,\n",
              " 'decision_function_shape': 'ovr',\n",
              " 'degree': 3,\n",
              " 'gamma': 'auto',\n",
              " 'kernel': 'rbf',\n",
              " 'max_iter': -1,\n",
              " 'probability': False,\n",
              " 'random_state': None,\n",
              " 'shrinking': True,\n",
              " 'tol': 0.001,\n",
              " 'verbose': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu_ubTL6YTDp",
        "outputId": "3c9aac40-dfc2-4fb0-fb88-8395164ca93d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
        "              'gamma': [0.1,0.01,0.001,0.0001], \n",
        "              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "              'break_ties' : [False,True],\n",
        "              'class_weight': ['balanced']\n",
        "}\n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, n_jobs = -1, scoring = 'recall_weighted',cv = 5) \n",
        "\n",
        "grid.fit(X_train_scaled, y_train)\n",
        "print(grid.best_params_)\n",
        "print(grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed: 11.7min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed: 20.7min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 32.1min\n",
            "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed: 32.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'C': 1, 'break_ties': False, 'class_weight': 'balanced', 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
            "SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='sigmoid',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UxIZ_dkrXRO"
      },
      "source": [
        "Classify using the best params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUSdcZbohXO2",
        "outputId": "8b892ffd-1c3f-4231-85b9-237e23f8c445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "grid_predictions = grid.best_estimator_.predict(X_test_scaled) \n",
        "print(\"Test Accuracy: \",metrics.accuracy_score(y_test,grid_predictions)*100)\n",
        "print(\"Test Precision: \",metrics.precision_score(y_test,grid_predictions,average='weighted')*100)\n",
        "print(\"Test Recall: \",metrics.recall_score(y_test,grid_predictions,average='weighted')*100)\n",
        "print(\"Test f1 score: \",metrics.f1_score(y_test,grid_predictions,average='weighted')*100)\n",
        "# print classification report\n",
        "print(metrics.classification_report(y_test, grid_predictions)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:  92.93333333333334\n",
            "Test Precision:  92.05329212807966\n",
            "Test Recall:  92.93333333333334\n",
            "Test f1 score:  92.23728557705503\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96      1364\n",
            "           1       0.67      0.43      0.53       136\n",
            "\n",
            "    accuracy                           0.93      1500\n",
            "   macro avg       0.81      0.71      0.74      1500\n",
            "weighted avg       0.92      0.93      0.92      1500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyraxEznrhIg"
      },
      "source": [
        "We can see clearly that both Precision and Recall have improved after tuning hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-hECtaAbhfb",
        "outputId": "28346e00-a7a9-44ca-c4d2-f8e8ae6f0efa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(grid_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le6xFAEHrpXp"
      },
      "source": [
        "Form a dataframe, containing the actual and predicted values of test data along with their indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBaoyE_cl1Rk",
        "outputId": "8a25d467-898b-47b1-f90a-cf1ba9bc9e8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df = pd.DataFrame({'Pred':pd.Series(grid_predictions),'Actual':pd.Series(y_test),'test_indices':pd.Series(indices_test)})\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pred</th>\n",
              "      <th>Actual</th>\n",
              "      <th>test_indices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2049</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pred  Actual  test_indices\n",
              "0     0       0          2191\n",
              "1     0       0           529\n",
              "2     0       0          2541\n",
              "3     0       0          2416\n",
              "4     0       0          2049"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmQyRMHArzBR"
      },
      "source": [
        "Find the comments that were classified as toxic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GYsQ3C-n5vh"
      },
      "source": [
        "toxic_comment_list = list(data.iloc[df[df['Pred']==1.0]['test_indices'].to_list()]['comment_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo9Rsr25r24H"
      },
      "source": [
        "Display the top 10 comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw0Q0ICso182",
        "outputId": "75c5673c-d60f-4ea0-bee3-990a08b72e25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "toxic_comment_list[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Piss Off \\r\\n\\r\\nSuck my dick you pussy',\n",
              " 'Fuck wiki\\r\\n\\r\\nFuck this piece of shit called Wikipedia, it bullshit of misinformation and Zionist propaganda! 188.23.179.183',\n",
              " \"The elephant population has tripled over the last decade... \\r\\n\\r\\nI'm not particularly fond of your level of douchebag.\",\n",
              " '\"\\r\\n\\r\\nATTENTION \"\"MIND CONTROLLED DIS INFO AGENT\"\"  KEEP IT REAL!  YOU THOUGHT YOU COULD USE WIKIPEDIA TO MISLEAD THE PUBLIC ABOUT ELECTRONIC HARASSMENT AND IT IS JUST NOT GOING TO HAPPEN.  YOU HAVE BEEN EXPOSED ESPECIALLY BY YOU UNPROFESSIONAL REMARKS ABOVE.\"',\n",
              " 'NIGHTSTALLIONS WIFE GOT FUCKED BY A NIGGER AND HAD HIS BABY\\r\\n\\r\\nAND IT SMELLED OF FRIED CHICKEN',\n",
              " \"Stop deleting my jont.  I told you! You can ask him he'll tell you that we're friends we went to the same preschool!\\r\\nStop being so damn ignorant.  I hate people like you. Yall think you're soo cool but really all u are is just a buttfart!  GO rub you're nipples sherlock.  Leave me alone!\",\n",
              " 'QUIT Threatening Me... \\r\\n\\r\\nBeyotch!!',\n",
              " 'Lets not edit user pages and look like a fucking moron, ok? Ok. Go home, little girl.',\n",
              " \"Hey you cunt armchair lawyer\\r\\nDo you like it? Sitting in your mom's basement trying to act like you are know it all?\\r\\n\\r\\nGo fuck yourself you stupid cunt bag.\",\n",
              " 'targeted by trigger happy admin']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVqUCqaCtS-3"
      },
      "source": [
        "Display the top 15 toxic words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5APs9uO8FGTV",
        "outputId": "e78e1a80-3456-4234-c1eb-b461c627123f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "toxicWordList, toxicCommentList = textPreProcess(toxic_comment_list)\n",
        "toxic_word_count = Counter(toxicWordList)\n",
        "toxic_word_count.most_common(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('assfuck', 277),\n",
              " ('gay', 212),\n",
              " ('fucking', 118),\n",
              " ('shit', 104),\n",
              " ('eat', 96),\n",
              " ('admins', 95),\n",
              " ('cocksucking', 94),\n",
              " ('cunts', 94),\n",
              " ('fuck', 16),\n",
              " ('bitch', 13),\n",
              " ('like', 10),\n",
              " ('dont', 10),\n",
              " ('stop', 8),\n",
              " ('talk', 8),\n",
              " ('cult', 8)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjVHqPtrtYqd"
      },
      "source": [
        "Lets try other Models and see if we get better recall values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwDs1YrrNi3z",
        "outputId": "c5428aeb-04fd-407f-f4ad-c3ac05d55bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train,y_train)\n",
        "ypred = model.predict(X_test)\n",
        "print(metrics.classification_report(y_test, ypred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96      1364\n",
            "           1       1.00      0.15      0.27       136\n",
            "\n",
            "    accuracy                           0.92      1500\n",
            "   macro avg       0.96      0.58      0.61      1500\n",
            "weighted avg       0.93      0.92      0.90      1500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tun0ipB6S_wB",
        "outputId": "ed853e62-4b55-44e6-c3f3-006d90cdda19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "C = [10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200]\n",
        "class_weight = ['dict', 'balanced', 'none']\n",
        "dual = [True,False]\n",
        "fit_intercept = [True,False]\n",
        "penalty = ['l1', 'l2', 'elasticnet', 'none']\n",
        "l1_ratio = [0,0.2,0.4,0.6,0.8,1]\n",
        "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "max_iter = [11000]\n",
        "random_grid = {'C': C,\n",
        "               'class_weight': class_weight,\n",
        "               'fit_intercept':fit_intercept,\n",
        "               'solver':solver,\n",
        "               'dual': dual,\n",
        "               'penalty': penalty,\n",
        "               'l1_ratio': l1_ratio,\n",
        "               'max_iter': max_iter\n",
        "              }\n",
        "print(random_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200], 'class_weight': ['dict', 'balanced', 'none'], 'fit_intercept': [True, False], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'dual': [True, False], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'l1_ratio': [0, 0.2, 0.4, 0.6, 0.8, 1], 'max_iter': [11000]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aasvn3AGTpZG",
        "outputId": "28aa621e-d3ec-4bf9-f6b7-a549e63fecb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "clf = LogisticRegression(random_state=0)\n",
        "clf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 1000, cv = 3, verbose=2, n_jobs = -1)\n",
        "clf_random.fit(X_train, y_train)\n",
        "clf_random.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1000 candidates, totalling 3000 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   33.0s\n",
            "[Parallel(n_jobs=-1)]: Done 299 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=-1)]: Done 732 tasks      | elapsed:  8.5min\n",
            "[Parallel(n_jobs=-1)]: Done 1414 tasks      | elapsed: 16.1min\n",
            "[Parallel(n_jobs=-1)]: Done 2033 tasks      | elapsed: 23.9min\n",
            "[Parallel(n_jobs=-1)]: Done 2780 tasks      | elapsed: 36.8min\n",
            "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed: 47.8min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 70,\n",
              " 'class_weight': 'balanced',\n",
              " 'dual': False,\n",
              " 'fit_intercept': True,\n",
              " 'l1_ratio': 0,\n",
              " 'max_iter': 11000,\n",
              " 'penalty': 'l1',\n",
              " 'solver': 'saga'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUcOxGYSTuhJ",
        "outputId": "6ced4c6e-4a8b-4978-ac16-c1b9f829e3bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "grid_predictions = clf_random.best_estimator_.predict(X_test) \n",
        "print(\"Test Accuracy: \",metrics.accuracy_score(y_test,grid_predictions)*100)\n",
        "print(\"Test Precision: \",metrics.precision_score(y_test,grid_predictions,average='weighted')*100)\n",
        "print(\"Test Recall: \",metrics.recall_score(y_test,grid_predictions,average='weighted')*100)\n",
        "print(\"Test f1 score: \",metrics.f1_score(y_test,grid_predictions,average='weighted')*100)\n",
        "# print classification report\n",
        "print(metrics.classification_report(y_test, grid_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:  94.73333333333333\n",
            "Test Precision:  94.30277796883479\n",
            "Test Recall:  94.73333333333333\n",
            "Test f1 score:  94.27972833626713\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      1364\n",
            "           1       0.81      0.55      0.66       136\n",
            "\n",
            "    accuracy                           0.95      1500\n",
            "   macro avg       0.88      0.77      0.81      1500\n",
            "weighted avg       0.94      0.95      0.94      1500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ7JvLVUfaY2",
        "outputId": "d62ed0a9-2d84-4539-dcc7-c2ddd50e6c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# evaluate predictions\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "recall = metrics.recall_score(y_test,y_pred,average='weighted')\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"recall weighted: %.2f%%\" % (recall * 100.0) )\n",
        "print(metrics.classification_report(y_test, y_pred, labels=[0,1]))\n",
        "\n",
        "scores = cross_val_score(model, finalFeatureApply, label, cv=5,scoring='recall_weighted')\n",
        "print(scores*100)\n",
        "print(\"mean recall_weighted score: \",scores.mean()*100,\"%\")\n",
        "print(\"std dev: \",scores.std()*100,\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 93.60%\n",
            "recall weighted: 93.60%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      1364\n",
            "           1       0.93      0.32      0.47       136\n",
            "\n",
            "    accuracy                           0.94      1500\n",
            "   macro avg       0.94      0.66      0.72      1500\n",
            "weighted avg       0.94      0.94      0.92      1500\n",
            "\n",
            "[94.4 93.5 94.6 93.4 93.5]\n",
            "mean recall_weighted score:  93.88000000000002 %\n",
            "std dev:  0.511468474101772 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvGLDdgdqXU3"
      },
      "source": [
        "Comparing all 3 Models, we see that Logistic Regression gives us the best Recall Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caKXWc7QqhYv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}